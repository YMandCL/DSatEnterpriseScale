{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras and TensorFlow on the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified from https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras library is a high level API that can be used to write cleaner Deep Learning code, and connects to many frameworks.  Here, we work with the TensorFlow framework.  \n",
    "MNIST is a dataset of handwritten numbers, and is used so frequently that a library exists to access the data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of 60,000 images, of 28 x 28 pixels each.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:  Describe the topology of the network here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default number of epochs is 12.  For non-GPU systems, each epoch can take longer than a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0254 - acc: 0.9919 - val_loss: 0.0270 - val_acc: 0.9919\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0263 - val_acc: 0.9912\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0222 - acc: 0.9928 - val_loss: 0.0277 - val_acc: 0.9917\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0317 - val_acc: 0.9911\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 70s 1ms/step - loss: 0.0214 - acc: 0.9930 - val_loss: 0.0286 - val_acc: 0.9916\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 70s 1ms/step - loss: 0.0194 - acc: 0.9940 - val_loss: 0.0281 - val_acc: 0.9915\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0365 - val_acc: 0.9897\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0200 - acc: 0.9938 - val_loss: 0.0289 - val_acc: 0.9918\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0194 - acc: 0.9937 - val_loss: 0.0286 - val_acc: 0.9927\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0289 - val_acc: 0.9917\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0198 - acc: 0.9938 - val_loss: 0.0287 - val_acc: 0.9930\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0190 - acc: 0.9944 - val_loss: 0.0270 - val_acc: 0.9928\n",
      "Test loss: 0.027031348173831383\n",
      "Test accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeing the Prediction in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras API is somewhat high level, and it is nice to be able to see where the moving parts are in the code.  To do that, we randomly select an image, predict its label, and compare our prediction to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image #:9374\n",
      "Class:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAg/kBThB5Ii/EBShB9I6v8AbpNBtSaoEGYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f570d4ffac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "imageNum = random.randint(1,len(x_test)) - 1 \n",
    "\n",
    "img = x_test[imageNum]\n",
    "test_img = img.reshape((1,784))\n",
    "#img_class = model.predict_classes(x_test)\n",
    "prediction = img_class[imageNum]\n",
    "classname = img_class[imageNum]\n",
    "print(\"Image #:\" + str(imageNum))\n",
    "print(\"Class: \",classname)\n",
    "\n",
    "img = img.reshape((28,28))\n",
    "plt.imshow(img)\n",
    "plt.title(classname)\n",
    "plt.show()\n",
    "#[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model metadata is saved as a `.json` file, while the model weights are saved in a separate HDF5 file, which is a compressed format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "filename = \"model-\" + str(epochs) + \"epochs\" \n",
    "model_json = model.to_json()\n",
    "with open(filename + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(filename + \".h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a peek at the weights for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10927654,  0.10947698, -0.03881344, -0.04827883,  0.23518483,\n",
       "         0.21955341,  0.2321063 ,  0.19014159,  0.11312762,  0.14508425,\n",
       "         0.32809755, -0.03462591, -0.29194313,  0.10265226, -0.25803047,\n",
       "        -0.02435865,  0.24643123, -0.016085  ,  0.10376387, -0.02634757,\n",
       "         0.12163555, -0.24826382,  0.03347541, -0.09186963, -0.2543182 ,\n",
       "         0.04574647,  0.24469429, -0.27173215,  0.2361595 ,  0.23593156,\n",
       "        -0.13275822,  0.01125437]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.get_weights()\n",
    "weights[0][0][0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reload this model and verify that it is performing exactly as the model that was saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open( filename + '.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights( filename + \".h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights should be exactly the same, with no roundoff error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10927654,  0.10947698, -0.03881344, -0.04827883,  0.23518483,\n",
       "         0.21955341,  0.2321063 ,  0.19014159,  0.11312762,  0.14508425,\n",
       "         0.32809755, -0.03462591, -0.29194313,  0.10265226, -0.25803047,\n",
       "        -0.02435865,  0.24643123, -0.016085  ,  0.10376387, -0.02634757,\n",
       "         0.12163555, -0.24826382,  0.03347541, -0.09186963, -0.2543182 ,\n",
       "         0.04574647,  0.24469429, -0.27173215,  0.2361595 ,  0.23593156,\n",
       "        -0.13275822,  0.01125437]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_weights = loaded_model.get_weights()\n",
    "loaded_weights[0][0][0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the performance of the trained model and the reloaded model to verify that we have the same model in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.027031348173831383\n",
      "Test accuracy: 0.9928\n",
      "acc: 99.28%\n",
      "Test loss: 0.027031348173831383\n",
      "Test accuracy: 0.9928\n",
      "acc: 99.28%\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print (\"Original Model Pero\")\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "score = loaded_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
