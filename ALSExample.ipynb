{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Alternating Least Squares Using Apache SystemML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses some material from the the original notebook in the SystemML repo:\n",
    "https://raw.githubusercontent.com/apache/systemml/master/samples/jupyter-notebooks/ALS_python_demo.ipynb\n",
    "\n",
    "\n",
    "Recommendation systems based on Alternating Least Squares (ALS) algorithm have gained popularity in recent years because, in general, they perform better as compared to content based approaches.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS is a matrix factorization algorithm, where a user-item matrix is factorized into two low-rank non-orthogonal matrices:\n",
    "\n",
    "$${\\bf R} = {\\bf U} {\\bf M}$$\n",
    "\n",
    "The elements, $r_{ij}$, of matrix $R$ can represent, for example, ratings assigned to the $j$th movie by the $i$th user.\n",
    "\n",
    "This matrix factorization assumes that each user can be described by $K$ latent features. Similarly, each item/movie can also be represented by $K$ latent features. The user rating of a particular movie can thus be approximated by the product of two $K$-dimensional vectors:\n",
    "\n",
    "$$r_{ij} = {\\bf u}_i^T {\\bf m}_j$$\n",
    "\n",
    "The vectors ${\\bf u}_i$ are rows of $U$ and ${\\bf m}_j$'s are columns of $M$. These can be learned by minimizing the cost function:\n",
    "\n",
    "$$f(U, M) = \\sum_{i,j} \\left( r_{ij} - {\\bf u}_i^T {\\bf m}_j \\right)^2 = \\| R - UM \\|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Model as a Latent Feature Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"score\" or label of a particular movie/user pair is\n",
    "$$r_{ij} = {\\bf u}_i^T {\\bf m}_j$$\n",
    "for the $i$th user and $j$th movie.  One way to think of the rank is in terms of the *movie score* only as a linear model:\n",
    "\n",
    "$$r_{ij} = \\sum_{k=1}^{K} \\alpha_k m_{j,k}$$\n",
    "\n",
    "where the movie vector is now represented as feature vector with $K$ features, and the user vector is simply a set of learned parameters from the data.  We define how many features this internal representation will have, but the resultant output is really the only thing we are concerned with.  These \"features\" are simply learned during the process of fitting the objective function, and may or may not be mapped to an actual, explainable feature set that we might understand.  As such, they are referred to as *latent features*.  In this sence, these latent features are akin to clusters that you might see in an unsupervised learning model, which makes this model an interesting hybrid model.\n",
    "\n",
    "Yet another way to think of the same score is the *user score* as a linear model:\n",
    "\n",
    "$$r_{ij} = \\sum_{k=1}^{K} \\beta_k u_{i,k}$$\n",
    "\n",
    "Now, the features are related to the user vector, and the parameters are learned weights.  In fact, the training process is an alternation between solving for the weights of the *movie vector* while holding the user features constant, and the weights for the *user vector* holding the movie features constant.  The numerical solution of the objective is obtained through this *alternating least squares* approach.  T\n",
    "\n",
    "If this model were not so popular and powerful, it might otherwise be considered an interesting peculiarity of machine learning.  It is however, the most widely used machine learning algorithm in e-commerce, and is particularly effective for *recommender sytems*, whereby a list of recommended items can be generated for new users based on the preferences of similar previous users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://rally1.fyre.ibm.com:4040)\" target=\"new_tab\">Spark UI: local-1543261122307</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark local-1543261122307: Some(http://rally1.fyre.ibm.com:4040)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.recommendation.ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using scala, we will leverage the convenience of a `case class` to package some of our parameter settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Parameters\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case class Parameters(filename: String, rank: Int = 5, numDSIterations: Int = 5, \n",
    "                  lambda: Double = 0.1, trainFraction: Double = 0.9, \n",
    "                  trainSeed: Long = 0L, splitSeed: Int = 0) {\n",
    "                      //JNDB TODO:  need to be typed.\n",
    "                      val testFraction = 1 - trainFraction\n",
    "                      val data = sc.textFile(filename)\n",
    "                      \n",
    "                      val Array(dataTrain, dataTest) = data.randomSplit(Array(trainFraction, testFraction), splitSeed)\n",
    "                      dataTrain.cache\n",
    "                      dataTest.cache\n",
    "                      val (trainNum, testNum) = (dataTrain.count, dataTest.count)\n",
    "                      val totalNum = trainNum - testNum\n",
    "                      val display = {\n",
    "                        \"filename: \" + filename  + \"\\n\" +\n",
    "                        \"rank: \" + rank.toString + \"\\n\" + \n",
    "                        \"lambda: \" + lambda.toString + \"\\n\" + \n",
    "                        \"# DS iterations: \" + numDSIterations.toString + \"\\n\" + \n",
    "                        \"trainingFraction: \" + trainFraction.toString  + \"\\n\" +\n",
    "                        \"training random seed: \" + trainSeed.toString  + \"\\n\" +\n",
    "                        \"splitting random seed: \" + splitSeed.toString + \"\\n\" + \n",
    "                        \"# (training, test, total) points:  \" + (testNum, trainNum, totalNum) + \"\\n\"  \n",
    "                    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a single case class with all of the information required to run our ALS prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p = Parameters(sample_movielens_ratings.txt,1500,15,0.1,0.9,0,0)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Parameters(sample_movielens_ratings.txt,1500,15,0.1,0.9,0,0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val p = Parameters(filename = \"sample_movielens_ratings.txt\", \n",
    "                              rank = 1500, \n",
    "                              numDSIterations = 15, \n",
    "                              lambda = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that will parse our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parseRating: (str: String)RatingML\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case class RatingML(userId: Int, movieId: Int, rating: Float, timestamp: Long)\n",
    "\n",
    "def parseRating(str: String): RatingML = {\n",
    "    val fields = str.split(\"::\")\n",
    "    assert(fields.size == 4)\n",
    "    RatingML(fields(0).toInt, fields(1).toInt, fields(2).toFloat, fields(3).toLong)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our `Parameters` class, we split our data into training and test sets.  Lets parse those raw ratings into a proper `DataFrame` so we can use the ML Pipelines API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val train = p.dataTrain.map(parseRating).toDF()\n",
    "val test = p.dataTest.map(parseRating).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Regularized ALS\n",
    "\n",
    "In this notebook, we'll implement ALS algorithm with _weighted-$\\lambda$-regularization_ formulated by [Zhou _et_. _al_](https://liuxiaofei.com.cn/blog/wp-content/uploads/2014/01/netflix_aaim08submitted.pdf). The cost function with such regularization is:\n",
    "\n",
    "$$f(U, M) = \\sum_{i,j} I_{ij}\\left( r_{ij} - {\\bf u}_i^T {\\bf m}_j \\right)^2 + \\lambda \\left( \\sum_i n_{u_i} \\| {\\bf u}\\|_i^2 + \\sum_j n_{m_j} \\|{\\bf m}\\|_j^2 \\right)$$\n",
    "\n",
    "\n",
    "Here, $\\lambda$ is the usual regularization parameter. $n_{u_i}$ and $n_{m_j}$ represent the number of ratings of user $i$ and movie $j$ respectively. $I_{ij}$ is an indicator variable such that $I_{ij} = 1$ if $r_{ij}$ exists and $I_{ij} = 0$ otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we fix ${\\bf m}_j$, we can determine ${\\bf u}_i$ by solving a regularized least squares problem:\n",
    "\n",
    "$$ \\frac{1}{2} \\frac{\\partial f}{\\partial {\\bf u}_i} = 0$$\n",
    "\n",
    "This gives the following matrix equation:\n",
    "\n",
    "$$\\left(M \\text{diag}({\\bf I}_i^T) M^{T} + \\lambda n_{u_i} E\\right) {\\bf u}_i = M {\\bf r}_i^T$$\n",
    "\n",
    "Here ${\\bf r}_i^T$ is the $i$th row of $R$. Similarly, ${\\bf I}_i$ the $i$th row of the matrix $I = [I_{ij}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the first few entries look like. We have a sparse mapping of users and movies to ratings.  The goal of the ALS algorithm is to predict the rating of a user/movie pairing that does not exist in the training dataset.  This is accomplished by creating a set of latent features (defined by the \"rank\" parameter here) from the training dataset and using those latent features to predict on new data.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     0|      2|   3.0|1424380312|\n",
      "|     0|      3|   1.0|1424380312|\n",
      "|     0|      5|   2.0|1424380312|\n",
      "|     0|      9|   4.0|1424380312|\n",
      "|     0|     11|   1.0|1424380312|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to compute (in seconds): 37.265\n",
      "time to compute (in minutes): 0.621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train = [userId: int, movieId: int ... 2 more fields]\n",
       "test = [userId: int, movieId: int ... 2 more fields]\n",
       "t0 = 3282565836121988\n",
       "als = als_6cdf7ac2d743\n",
       "model = als_6cdf7ac2d743\n",
       "predictions = [userId: int, movieId: int ... 3 more fields]\n",
       "predictionsWithDeltas = [userID: int, movieID: int ... 3 more fields]\n",
       "t1 = 3282603101118972\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3282603101118972"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val t0 = System.nanoTime\n",
    "  // Build the recommendation model using ALS on the training data\n",
    "val als = new ALS \n",
    "als.\n",
    "  setMaxIter(p.numDSIterations).\n",
    "  setRank(p.rank).\n",
    "  setRegParam(p.lambda).\n",
    "  setUserCol(\"userId\").\n",
    "  setItemCol(\"movieId\").\n",
    "  setRatingCol(\"rating\")\n",
    "val model = als.fit(train)\n",
    "     \n",
    "  // Evaluate the model by computing the RMSE on the test data\n",
    "val predictions = model.transform(test)\n",
    "predictions.createOrReplaceTempView(\"predictions\")\n",
    "val predictionsWithDeltas = spark.sql(\"select userID, movieID, rating, round(prediction), (rating - prediction) as delta from predictions\")\n",
    "    \n",
    "val t1 = System.nanoTime\n",
    "\n",
    "println(\"time to compute (in seconds): \"  + Math.round((t1-t0) / 1.0e6) / 1.0e3 )\n",
    "println(\"time to compute (in minutes): \"  + Math.round((t1-t0) / 60.0 / 1.0e6) / 1.0e3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+--------------------+------------+\n",
      "|userID|movieID|rating|round(prediction, 0)|       delta|\n",
      "+------+-------+------+--------------------+------------+\n",
      "|    26|     31|   1.0|                 0.0|  0.52631253|\n",
      "|     5|     31|   1.0|                 1.0| -0.03673148|\n",
      "|    25|     31|   2.0|                 2.0| -0.23639536|\n",
      "|    15|     85|   1.0|                 1.0| -0.45566332|\n",
      "|    21|     85|   3.0|                 3.0|  0.37177014|\n",
      "|    28|     65|   1.0|                 1.0| -0.10253787|\n",
      "|    23|     65|   5.0|                 2.0|   2.9174232|\n",
      "|    24|     65|   1.0|                 1.0|-0.029762268|\n",
      "|    27|     78|   1.0|                 1.0|  0.23632115|\n",
      "|     4|     78|   1.0|                 1.0|  0.14433408|\n",
      "|    21|     81|   1.0|                 1.0| -0.08326793|\n",
      "|    18|     28|   5.0|                 1.0|   3.9147174|\n",
      "|     6|     26|   1.0|                 1.0| -0.22810721|\n",
      "|    15|     26|   3.0|                 1.0|   1.7759048|\n",
      "|    26|     27|   1.0|                 2.0| -0.89232457|\n",
      "|    28|     44|   1.0|                 1.0| -0.38535595|\n",
      "|    27|     44|   3.0|                 1.0|   1.7167155|\n",
      "|    22|     44|   1.0|                 1.0|  0.18374622|\n",
      "|     9|     12|   1.0|                 1.0| 0.082620144|\n",
      "|     0|     12|   2.0|                 3.0|  -0.5936291|\n",
      "+------+-------+------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsWithDeltas.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: sample_movielens_ratings.txt\n",
      "rank: 1500\n",
      "lambda: 0.1\n",
      "# DS iterations: 15\n",
      "trainingFraction: 0.9\n",
      "training random seed: 0\n",
      "splitting random seed: 0\n",
      "# (training, test, total) points:  (154,1347,1193)\n",
      "\n",
      "# test points: 154\n",
      "rmse: 1.0696576978925214\n",
      "correct predictions: 83\n",
      "incorrect predictions:71\n",
      "# predictions: 154\n",
      "accuracy: 0.538961038961039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count = 154\n",
       "rmse = 1.0696576978925214\n",
       "truePositives = 83\n",
       "falsePositives = 71\n",
       "accuracy = 0.538961038961039\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.538961038961039"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val count = predictionsWithDeltas.count\n",
    "// RMSE (root mean squared error) is computed in the usual way\n",
    "val rmse = Math.sqrt(predictionsWithDeltas.select(\"delta\").map(x => Math.pow(x(0).asInstanceOf[Float], 2)).reduce(_+_)/count) \n",
    "// A true positive is defined as a prediction that lands within 0.5 of the correct prediction (using delta column)\n",
    "val truePositives =  predictionsWithDeltas.select(\"delta\").filter(x=>Math.abs(x(0).asInstanceOf[Float]) <= 0.5).count \n",
    "val falsePositives = count - truePositives\n",
    "val accuracy = truePositives.toDouble/count.toDouble\n",
    "\n",
    "println(p.display)\n",
    "println(\"# test points: \" + count)\n",
    "println(\"rmse: \" + rmse)\n",
    "println(\"correct predictions: \" + truePositives)\n",
    "println(\"incorrect predictions:\" + falsePositives)\n",
    "println(\"# predictions: \" + count)\n",
    "println(\"accuracy: \" + accuracy)\n",
    "\n",
    "//println(\"time to compute (in seconds): \"  + Math.round((t1-t0) / 1.0e6) / 1.0e3 )\n",
    "//println(\"time to compute (in minutes): \"  + Math.round((t1-t0) / 60.0 / 1.0e6) / 1.0e3 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
