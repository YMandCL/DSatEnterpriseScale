{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Click Stream Data with the GraphX Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maxEdgesFirstShell = 25\n",
       "maxEdgesNthShell = 20\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val maxEdgesFirstShell = 25\n",
    "val maxEdgesNthShell = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a look at the Wikipedia ClickStream Dataset (TODO:  Link to original dataset).  This dataset reports thee number of times a user goes from one Wikipedia site to another.  The first two columns are the page numbers of the \"from\" site and \"to\" site, respectively (as indexed numbers).  The third column is the the number of clicks (the edge values).  The remaining columns are the \"from\" and \"to\" sites (as names). If a \"from\" site is outside of the Wikipedia corpus, it is listed as \"other\".  We will remove these sites, because it is not interesting to count those entries, and the numbers are much larger than the clickstream traffic within Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.hadoop.mapred.InvalidInputException\n",
       "Message: Input path does not exist: file:/Users/nilmeier@us.ibm.com/Box Sync/git/DSatEnterpriseScale/headPlusWatsonPlusTeslaPlusApple.tsv\n",
       "StackTrace:   at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\n",
       "  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n",
       "  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n",
       "  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n",
       "  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n",
       "  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n",
       "  at scala.Option.getOrElse(Option.scala:121)\n",
       "  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n",
       "  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n",
       "  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n",
       "  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n",
       "  at scala.Option.getOrElse(Option.scala:121)\n",
       "  at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n",
       "  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1333)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
       "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n",
       "  at org.apache.spark.rdd.RDD.take(RDD.scala:1327)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lines = sc.textFile(\"headPlusWatsonPlusTeslaPlusApple.tsv\")\n",
    "lines.take(20).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Some ETL Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some ETL that we will need to carry out in order to get a graph model that is worth using.  One such function is a simple indexing of the \"other\" sites so that we can filter them out later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n",
       "getIndex: (x: String)Int\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// simple mapping of 'other names to a unique index'\n",
    "def getIndex(x: String): Int = x match {\n",
    "    case \"other-wikipedia\" => 1\n",
    "    case \"other-empty\"     => 2\n",
    "    case \"other-internal\"  => 3    \n",
    "    case \"other-google\"    => 4\n",
    "    case \"other-yahoo\"     => 5\n",
    "    case \"other-bing\"      => 6\n",
    "    case \"other-facebook\"  => 7\n",
    "    case \"other-twitter\"   => 8 \n",
    "    case \"other-other\"     => 9 \n",
    "    case _ => 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more ETL Functions here.  We need to populate empty fields with null values that have the same type.  The API here is a bit less robust than the DataFrames API, but nothing we can't handle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assignOtherSourceIndex: (partsLine: Array[String])String\n",
       "fillWithNum: (element: String)String\n",
       "fillWithString: (element: String, colNum: Int)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def assignOtherSourceIndex(partsLine:Array[String]): String = {\n",
    "    println( \"assigning other source to \" + partsLine(0))\n",
    "    if (partsLine(0) == \"\") {\n",
    "//      println(\"empty\")\n",
    "      return getIndex(partsLine(3)).toString\n",
    "    }\n",
    "    else {\n",
    "//       println(\"in nonblank\")\n",
    "       return partsLine(0)\n",
    "    }\n",
    "}\n",
    "// filling empty number fields with a large number\n",
    "def fillWithNum(element: String): String = {\n",
    "    if (element == \"\"){ 999999999.toString }\n",
    "    else {element}\n",
    "}\n",
    "\n",
    "// filling empty column fields with a filler string\n",
    "def fillWithString(element: String, colNum: Int): String = {\n",
    "    if (element == \"\"){\"column\"+colNum+\"Fill\"}\n",
    "    else{element}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to take our raw RDD and add all of our ETL functions.  We're filtering out redlinks, as well as all clicktstreams from outside Wikipedia, and also handling empty fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:31: error: not found: value lines\n",
       "       val parts = lines.map(l=>l.split(\"\\t\")).filter(l => !(l.contains(\"redlink\"))). //splitting on tabs and filtering out redlinks\n",
       "                   ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parts = lines.map(l=>l.split(\"\\t\")).filter(l => !(l.contains(\"redlink\"))). //splitting on tabs and filtering out redlinks\n",
    "                                                    map(l => Array(assignOtherSourceIndex(l), \n",
    "                                                    fillWithNum(l(1)),fillWithNum(l(2)),\n",
    "                                                    fillWithString(l(3),4),fillWithString(l(4),5))).\n",
    "                                                    filter(y=>y(0).toInt>9)\n",
    "\n",
    "parts.take(20).foreach(x => println(x(0)+\"\\t\" + x(1) + \"\\t\" + x(2) + \"\\t\" + x(3) + \"\\t\" + x(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert this into a DataFrame.  For this notebook, the DataFrame is only used briefly to show the column labels.  The `parts` RDD is used to construct the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Fields\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case class Fields(prev_id: Int, curr_id: Int, n: Int, \n",
    "           prev_title: String, curr_title: String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:27: error: not found: value parts\n",
       "       val clicksDataFrame = parts.map(\n",
       "                             ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val clicksDataFrame = parts.map(\n",
    "     p => Fields(p(0).toInt, p(1).toInt, p(2).toInt, p(3), p(4))).toDF\n",
    "\n",
    "// registering dataframe\n",
    "clicksDataFrame.registerTempTable(\"clicks\")\n",
    "clicksDataFrame.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to explicitly deduplicate our vertices before building the graph.  The graphX API will handle this for us, but It saves us some time later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:26: error: not found: value parts\n",
       "       val nodes1 = (parts.map{p => Array(p(0).toString, p(3)) })\n",
       "                     ^\n",
       "<console>:31: error: not found: value parts\n",
       "       val nodes2 = (parts.map{p => Array(p(1).toString, p(4)) })\n",
       "                     ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//nodes should be deduplicated\n",
    "val nodes1 = (parts.map{p => Array(p(0).toString, p(3)) })\n",
    "nodes1.cache()\n",
    "val uniqueNodes1 = nodes1.map(x => x(0)+\"-0-\"+x(1)).distinct.  //trick for accessing distinct\n",
    "    map(x => Array(x.split(\"-0-\")(0), x.split(\"-0-\")(1)))  //resplitting to original structure\n",
    "\n",
    "val nodes2 = (parts.map{p => Array(p(1).toString, p(4)) })\n",
    "nodes2.cache()             \n",
    "val uniqueNodes2 = nodes2.map(x => x(0)+\"-0-\"+x(1)).distinct.  //trick for accessing distinct\n",
    "    map(x => Array(x.split(\"-0-\")(0), x.split(\"-0-\")(1)))  //resplitting to original structure\n",
    "                         //converting to vertex RDD\n",
    "\n",
    "\n",
    "uniqueNodes1.cache\n",
    "uniqueNodes2.cache\n",
    "val uniqueNodesBoth = (uniqueNodes1 ++ uniqueNodes2).map(x => x(0)+\"-0-\"+x(1)).distinct.  //trick for accessing distinct\n",
    "    map(x=>Array(x.split(\"-0-\")(0), x.split(\"-0-\")(1))).  //resplitting to original structure\n",
    "    map{ x=> (x(0).toInt.toLong, (x(1), x(1))) }  \n",
    "uniqueNodesBoth.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct the graph.  A graph consists of an RDD of vertices, and an RDD of edges, along with some error handling for dangling edges.  A printout of the first 10 edges and vertices is listed below.  Note that the vertices have some extra label annotation, while the edges have only the integer indexing and the edge value.  This is because the edges RDD is much larger than the vertices RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:17: error: not found: value parts\n",
       "       val edges = parts.map(x => Edge(x(0).toInt.toLong,x(1).toInt.toLong, x(2)) )\n",
       "                   ^\n",
       "<console>:22: error: not found: value uniqueNodesBoth\n",
       "Error occurred in an application involving default arguments.\n",
       "       val graph = Graph(uniqueNodesBoth,edges,defaultNode)\n",
       "                         ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// importing the graphx library\n",
    "import org.apache.spark.graphx._\n",
    "case class nodeFields(nodeID: Int, nodeName: String)\n",
    " \n",
    "val edges = parts.map(x => Edge(x(0).toInt.toLong,x(1).toInt.toLong, x(2)) )\n",
    "val defaultNode = (\"default Node\", \"Missing\")\n",
    "\n",
    "//Graph is a wrapper to a vertex list and a edge list, with the defaultNode as well.\n",
    "//It does some internal bookkeepping to maintain consistency before packaging.\n",
    "val graph = Graph(uniqueNodesBoth,edges,defaultNode)\n",
    "//main graph will be searched very frequently\n",
    "graph.cache()\n",
    "\n",
    "println(\"\\nfirst 10 vertices\")\n",
    "graph.vertices.take(10).foreach(println)\n",
    "\n",
    "println(\"\\nfirst 10 edges\")\n",
    "graph.edges.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the top N edges connected to any particular node and discard the remaining edges.  This is known as graph pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:26: error: not found: type Graph\n",
       "                                                           Graph[(String, String),String] = {\n",
       "                                                           ^\n",
       "<console>:25: error: not found: type Graph\n",
       "       def pruneGraphByMaxEdges(maxEdges: Int,  bigGraph:  Graph[(String, String),String]):\n",
       "                                                           ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pruneGraphByMaxEdges(maxEdges: Int,  bigGraph:  Graph[(String, String),String]): \n",
    "                                                    Graph[(String, String),String] = {\n",
    "    val minCount = bigGraph.triplets.sortBy(_.attr.toInt, ascending=false).\n",
    "                                    map(x=>x.attr.toInt).take(maxEdges).reverse(0)\n",
    "\n",
    "    return bigGraph.subgraph(epred = x => x.attr.toInt >= minCount)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our pruning function in hand, we want to start with a particular node and build a *shell* of N nodes around that central node.   ONce that graph is built, we want to add a shell to each node of that graph.  We can do this as many times as we like, but we're only creating 3 shells in this notebook.  Ultimately, this will give us a list of all important wikipedia sites that are 4 clicks or less away from the source site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:27: error: not found: type Graph\n",
       "       def addShellToGraph(thisGraph: Graph[(String, String),String], shellNum:Int ): Graph[(String, String),String]  = {\n",
       "                                                                                      ^\n",
       "<console>:27: error: not found: type Graph\n",
       "       def addShellToGraph(thisGraph: Graph[(String, String),String], shellNum:Int ): Graph[(String, String),String]  = {\n",
       "                                      ^\n",
       "<console>:30: error: not found: type Graph\n",
       "           def recursiveGraphBuild(i:Int,prevGraph: Graph[(String, String),String] ):Graph[(String, String),String] = {\n",
       "                                                                                     ^\n",
       "<console>:30: error: not found: type Graph\n",
       "           def recursiveGraphBuild(i:Int,prevGraph: Graph[(String, String),String] ):Graph[(String, String),String] = {\n",
       "                                                    ^\n",
       "<console>:32: error: not found: value pruneGraphByMaxEdges\n",
       "               val currentGraph =  pruneGraphByMaxEdges(maxEdgesNthShell,\n",
       "                                   ^\n",
       "<console>:33: error: not found: value graph\n",
       "                                   graph.subgraph(epred = x => x.srcAttr._1 == searchStringList(i))\n",
       "                                   ^\n",
       "<console>:33: error: not found: value epred\n",
       "                                   graph.subgraph(epred = x => x.srcAttr._1 == searchStringList(i))\n",
       "                                                  ^\n",
       "<console>:36: error: not found: value Graph\n",
       "               val nextGraph = Graph( graph.vertices,\n",
       "                               ^\n",
       "<console>:36: error: not found: value graph\n",
       "               val nextGraph = Graph( graph.vertices,\n",
       "                                      ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addShellToGraph(thisGraph: Graph[(String, String),String], shellNum:Int ): Graph[(String, String),String]  = {\n",
    "\n",
    "    val searchStringList = thisGraph.triplets.map(x => x.srcAttr._1).collect\n",
    "    def recursiveGraphBuild(i:Int,prevGraph: Graph[(String, String),String] ):Graph[(String, String),String] = {\n",
    "        \n",
    "        val currentGraph =  pruneGraphByMaxEdges(maxEdgesNthShell,\n",
    "                            graph.subgraph(epred = x => x.srcAttr._1 == searchStringList(i))\n",
    "                            )\n",
    "\n",
    "        val nextGraph = Graph( graph.vertices, \n",
    "                                (prevGraph.edges++currentGraph.edges).distinct     )\n",
    "\n",
    "        if (i == searchStringList.length - 1 ) {   \n",
    "            return nextGraph\n",
    "        }\n",
    "        else {return recursiveGraphBuild(i+1, nextGraph)}\n",
    "    }\n",
    "    var i = 0\n",
    "    return recursiveGraphBuild(0,thisGraph)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's build our clickstream graph!  We'll start with the Watson site.  Some other sites are listed there as well.  Feel free to return to this and generate graphs with those after runnig through the first example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "centerVertex = Watson_(computer)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Watson_(computer)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// MAIN QUERY  ============================================\n",
    "//Here are a list of sites that work well for the prototype dataset\n",
    "\n",
    "val centerVertex = \"Watson_(computer)\"\n",
    "//val centerVertex = \"Heroes\"\n",
    "//val centerVertex = \"Tesla_Motors\"\n",
    "//val centerVertex = \"Apple_Inc.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate the first cell of sites around the center vertex (Watson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:29: error: not found: value pruneGraphByMaxEdges\n",
       "       val smallGraph = pruneGraphByMaxEdges(maxEdgesFirstShell,\n",
       "                        ^\n",
       "<console>:30: error: not found: value graph\n",
       "                        graph.subgraph(epred = x => x.dstAttr._1.contains(centerVertex) &&\n",
       "                        ^\n",
       "<console>:30: error: not found: value epred\n",
       "                        graph.subgraph(epred = x => x.dstAttr._1.contains(centerVertex) &&\n",
       "                                       ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val smallGraph = pruneGraphByMaxEdges(maxEdgesFirstShell, \n",
    "                 graph.subgraph(epred = x => x.dstAttr._1.contains(centerVertex) && \n",
    "                               !(x.srcAttr._1.contains(\"other-\")) && \n",
    "                               !(x.srcAttr._1 == \"Main_Page\"))\n",
    "                )\n",
    "smallGraph.cache\n",
    "//smallGraph.triplets.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of *all* of the vertices connected to Watson.  We'll build our larger graph from this one.  We're calling the `triplets` method, which returns the edge between two vertices (one is always Watson)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:26: error: not found: value smallGraph\n",
       "       smallGraph.triplets.collect.foreach(println)\n",
       "       ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallGraph.triplets.collect.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build out the additional shells from this original graph.  We're using a very small dataset here, so it only takes about a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:31: error: not found: value addShellToGraph\n",
       "       val graph1p1 = addShellToGraph(smallGraph,2)\n",
       "                      ^\n",
       "<console>:31: error: not found: value smallGraph\n",
       "       val graph1p1 = addShellToGraph(smallGraph,2)\n",
       "                                      ^\n",
       "<console>:32: error: not found: value addShellToGraph\n",
       "       val graph2p1 = addShellToGraph(graph1p1,3)\n",
       "                      ^\n",
       "<console>:34: error: not found: value addShellToGraph\n",
       "       val graph3p1 = addShellToGraph(graph2p1,4)\n",
       "                      ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//smallGraph.triplets.count\n",
    "val maxEdgesPerFirstShell = 50\n",
    "val maxEdgesPerNthShell = 20\n",
    "\n",
    "val t0 = System.nanoTime\n",
    "// called 3 times (manually)\n",
    "val graph1p1 = addShellToGraph(smallGraph,2)\n",
    "val graph2p1 = addShellToGraph(graph1p1,3)\n",
    "// fourth click takes longer and is not very informative (so far)\n",
    "val graph3p1 = addShellToGraph(graph2p1,4)\n",
    "//val graph2 = graph3p1\n",
    "graph3p1.edges.count \n",
    "val dt = ((System.nanoTime-t0)/1.0e6.round/1.0e3).toString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using scala here, we're just going to output the graph as a webpage that we will visualize in a separate page.  The rest of the code here is just reformatting and writing an html file that uses the d3 library.  After this has been run, go to the `site` directory and type:\n",
    "\n",
    "`(py35) python -m http.server`\n",
    "\n",
    "and go to `localhost:8000` (or `remotehost:8000`) to see your graph!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:27: error: not found: value graph3p1\n",
       "       val outputVertexList = (graph3p1.triplets.map(x=>x.srcAttr._1) ++ graph3p1.triplets.map(x=>x.dstAttr._1)).distinct\n",
       "                               ^\n",
       "<console>:27: error: not found: value graph3p1\n",
       "       val outputVertexList = (graph3p1.triplets.map(x=>x.srcAttr._1) ++ graph3p1.triplets.map(x=>x.dstAttr._1)).distinct\n",
       "                                                                         ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val outputVertexList = (graph3p1.triplets.map(x=>x.srcAttr._1) ++ graph3p1.triplets.map(x=>x.dstAttr._1)).distinct\n",
    "\n",
    "// getting unique indices for vertices that will be referenced in the 'links' section of the json output.\n",
    "val outputVertexListZipped=outputVertexList.collect.zipWithIndex\n",
    "\n",
    "def getLinkIndex(name: String): Int = { outputVertexListZipped.filter(x=>x._1==name)(0)._2}\n",
    "centerVertex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:35: error: not found: value graph3p1\n",
       "val maxEdgeVal = graph3p1.triplets.sortBy(_.attr.toInt, ascending=false).\n",
       "                 ^\n",
       "<console>:35: error: not found: value ascending\n",
       "val maxEdgeVal = graph3p1.triplets.sortBy(_.attr.toInt, ascending=false).\n",
       "                                                        ^\n",
       "<console>:42: error: not found: value outputVertexList\n",
       "val jsonVertices = outputVertexList.map(x=>x.replace(\"\"\"\\\"\"\" ,\"\"\"\\\\\"\"\")). // backslash\n",
       "                   ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// JSON WRITING ===========================================\n",
    "import sys.process._\n",
    "import java.io._\n",
    "\n",
    "val dirname = \"site\"\n",
    "val pw = new PrintWriter(new File(dirname + \"/\" + centerVertex + \".json\"))\n",
    "\n",
    "// a quick way to normalize edges (not rigorous):\n",
    "val maxEdgeVal = graph3p1.triplets.sortBy(_.attr.toInt, ascending=false).\n",
    "                                        map(x=>x.attr.toInt).take(1)(0)\n",
    "\n",
    "// recall that only *edges* are filtered, the full node list is kept at all times. \n",
    "// (it saves time when rebuilding Graphs)\n",
    "       \n",
    "//formatting vertices (lots of delimiter issues)                        \n",
    "val jsonVertices = outputVertexList.map(x=>x.replace(\"\"\"\\\"\"\" ,\"\"\"\\\\\"\"\")). // backslash\n",
    "                                    map(x=>x.replace(\"\\\"\",\"\\\\\\\"\")). // quote delimiters\n",
    "                                    map(x=>\"    {\\\"name\\\":\\\"\" + x + \"\\\",\\\"group\\\":1}\").\n",
    "                                    collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:25: error: not found: value graph3p1\n",
       "       val jsonEdges = graph3p1.triplets.map(x => (x.srcAttr._1,x.dstAttr._1,x.attr)).collect.map(y =>\n",
       "                       ^\n",
       "<console>:26: error: not found: value getLinkIndex\n",
       "                                           \"    {\\\"source\\\":\" + getLinkIndex(y._1).toString +\n",
       "                                                                ^\n",
       "<console>:27: error: not found: value getLinkIndex\n",
       "                                           \",\\\"target\\\":\" + getLinkIndex(y._2).toString +\n",
       "                                                            ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val jsonEdges = graph3p1.triplets.map(x => (x.srcAttr._1,x.dstAttr._1,x.attr)).collect.map(y =>  \n",
    "                                    \"    {\\\"source\\\":\" + getLinkIndex(y._1).toString +\n",
    "                                    \",\\\"target\\\":\" + getLinkIndex(y._2).toString +\n",
    "                                    \",\\\"value\\\":\" + (y._3.toFloat/maxEdgeVal*100).ceil.toInt.\n",
    "                                    toString  + \"}\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:37: error: not found: value pw\n",
       "       pw.write(\"  \\\"links\\\":[\\n\")\n",
       "       ^\n",
       "<console>:27: error: not found: value pw\n",
       "       pw.write(\"{\\n\")                             // main header\n",
       "       ^\n",
       "<console>:28: error: not found: value pw\n",
       "       pw.write(\"  \\\"nodes\\\":[\\n\")                 // nodes header\n",
       "       ^\n",
       "<console>:30: error: not found: value jsonVertices\n",
       "       for (i<-0 until jsonVertices.length){       // nodes\n",
       "                       ^\n",
       "<console>:31: error: not found: value pw\n",
       "           if(i == jsonVertices.length-1){pw.write(jsonVertices(i))}\n",
       "                                          ^\n",
       "<console>:31: error: not found: value jsonVertices\n",
       "           if(i == jsonVertices.length-1){pw.write(jsonVertices(i))}\n",
       "                                                   ^\n",
       "<console>:32: error: not found: value pw\n",
       "           else {pw.write(jsonVertices(i)+\",\")}\n",
       "                 ^\n",
       "<console>:32: error: not found: value jsonVertices\n",
       "           else {pw.write(jsonVertices(i)+\",\")}\n",
       "                          ^\n",
       "<console>:33: error: not found: value pw\n",
       "           pw.write(\"\\n\")}\n",
       "           ^\n",
       "<console>:34: error: not found: value pw\n",
       "       pw.write(\"  ],\\n\")                          // end nodes header\n",
       "       ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// writing json\n",
    "\n",
    "pw.write(\"{\\n\")                             // main header\n",
    "pw.write(\"  \\\"nodes\\\":[\\n\")                 // nodes header\n",
    "\n",
    "for (i<-0 until jsonVertices.length){       // nodes\n",
    "    if(i == jsonVertices.length-1){pw.write(jsonVertices(i))}\n",
    "    else {pw.write(jsonVertices(i)+\",\")}\n",
    "    pw.write(\"\\n\")}\n",
    "pw.write(\"  ],\\n\")                          // end nodes header\n",
    "pw.write(\"  \\\"links\\\":[\\n\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:34: error: not found: value pw\n",
       "       pw.close\n",
       "       ^\n",
       "<console>:25: error: not found: value jsonEdges\n",
       "       for (i<-0 until jsonEdges.length){          // links\n",
       "                       ^\n",
       "<console>:26: error: not found: value pw\n",
       "           if(i == jsonEdges.length-1){pw.write(jsonEdges(i))}\n",
       "                                       ^\n",
       "<console>:26: error: not found: value jsonEdges\n",
       "           if(i == jsonEdges.length-1){pw.write(jsonEdges(i))}\n",
       "                                                ^\n",
       "<console>:27: error: not found: value pw\n",
       "           else {pw.write(jsonEdges(i)+\",\")}\n",
       "                 ^\n",
       "<console>:27: error: not found: value jsonEdges\n",
       "           else {pw.write(jsonEdges(i)+\",\")}\n",
       "                          ^\n",
       "<console>:28: error: not found: value pw\n",
       "           pw.write(\"\\n\")\n",
       "           ^\n",
       "<console>:30: error: not found: value pw\n",
       "       pw.write(\"  ]\\n\")\n",
       "       ^\n",
       "<console>:31: error: not found: value pw\n",
       "       pw.write(\"}\")                               // main footer\n",
       "       ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (i<-0 until jsonEdges.length){          // links\n",
    "    if(i == jsonEdges.length-1){pw.write(jsonEdges(i))}\n",
    "    else {pw.write(jsonEdges(i)+\",\")}\n",
    "    pw.write(\"\\n\")\n",
    "}\n",
    "pw.write(\"  ]\\n\") \n",
    "pw.write(\"}\")                               // main footer\n",
    "pw.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:29: error: not found: value dirname\n",
       "       val lines = fromFile(dirname +\"/template.html\").getLines.toArray\n",
       "                            ^\n",
       "<console>:30: error: not found: type File\n",
       "       val pw = new java.io.PrintWriter(new File(dirname+\"/\"+centerVertex+\".html\"))\n",
       "                                            ^\n",
       "<console>:30: error: not found: value dirname\n",
       "       val pw = new java.io.PrintWriter(new File(dirname+\"/\"+centerVertex+\".html\"))\n",
       "                                                 ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// writing new html file from template\n",
    "import scala.io.Source._\n",
    "val lines = fromFile(dirname +\"/template.html\").getLines.toArray\n",
    "val pw = new java.io.PrintWriter(new File(dirname+\"/\"+centerVertex+\".html\"))\n",
    "\n",
    "//lines.map(x=>x.replace(\"NAME_OF_SITE\", centerVertex)).foreach(y=>pw.write(y+\"\\n\"))\n",
    "lines.map(x => x.replace(\"NAME_OF_SITE\", centerVertex)). \n",
    "      map(x => x.replace(\"TIME_FOR_QUERY\", \" (took \" + dt + \"s)\")).\n",
    "      foreach(y=>pw.write(y+\"\\n\"))\n",
    "\n",
    "pw.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
