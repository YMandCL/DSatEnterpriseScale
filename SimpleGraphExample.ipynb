{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Graph Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is taken from the Apache Spark Documentation.  It is a great example that shows the basic structure of the `Graph` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.graphx._\n",
    "// To make some of the examples work we will also need RDD\n",
    "import org.apache.spark.rdd.RDD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph consists of vertices (sometimes called nodes), and edges.  \n",
    "\n",
    "Edges are connections between vertices.  The connection can be a numeric value, or a word.  Usually, the word indicates a relationship between the vertices.  For example, \"A likes B\" indicates that vertex A and B are connected by an edge $e_{AB}=$ \"likes\"\n",
    "In Apache Spark, the graphs are *directed*, which means that a relationship between A and B can be different than B and A.  \n",
    "For example, the relationships \"A likes B\" and \"B dislikes A\" is a valid relationship (although very sad for A).\n",
    "\n",
    "To create a graph, we simply create a list of vertices and a list of edges (connections).  Once we have these, and have enforced some self-consistency requirements, we can create the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "users = ParallelCollectionRDD[26] at parallelize at <console>:40\n",
       "relationships = ParallelCollectionRDD[27] at parallelize at <console>:45\n",
       "defaultUser = (John Doe,Missing)\n",
       "graph = org.apache.spark.graphx.impl.GraphImpl@5cb896\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@5cb896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create an RDD for the vertices\n",
    "val users: RDD[(VertexId, (String, String))] =\n",
    "  sc.parallelize(Array((3L, (\"rxin\", \"student\")), (7L, (\"jgonzal\", \"postdoc\")),\n",
    "                       (5L, (\"franklin\", \"prof\")), (2L, (\"istoica\", \"prof\")),\n",
    "                       (4L, (\"peter\", \"student\"))))\n",
    "// Create an RDD for edges\n",
    "val relationships: RDD[Edge[String]] =\n",
    "  sc.parallelize(Array(Edge(3L, 7L, \"collab\"),    Edge(5L, 3L, \"advisor\"),\n",
    "                       Edge(2L, 5L, \"colleague\"), Edge(5L, 7L, \"PI\"),\n",
    "                       Edge(4L, 0L, \"student\"),   Edge(5L, 0L, \"colleague\")))\n",
    "// Define a default user in case there are relationship with missing user\n",
    "val defaultUser = (\"John Doe\", \"Missing\")\n",
    "\n",
    "// Build the initial Graph\n",
    "val graph = Graph(users, relationships, defaultUser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things explicit, let's call the vertices method and see what the structure looks like.  The vertex contains both an index and two different labels that can be accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,(John Doe,Missing))\n",
      "(2,(istoica,prof))\n",
      "(3,(rxin,student))\n",
      "(4,(peter,student))\n",
      "(5,(franklin,prof))\n",
      "(7,(jgonzal,postdoc))\n"
     ]
    }
   ],
   "source": [
    "graph.vertices.collect.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `edges` method returns only the index names of the vertices that are connected, along with the relationship.  Notice that the connection to 0 is actually a dangling edge, and we have assigned that to a \"default user\".  This is a bit of error handling for the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge(3,7,collab)\n",
      "Edge(5,3,advisor)\n",
      "Edge(2,5,colleague)\n",
      "Edge(5,7,pi)\n",
      "Edge(4,0,student)\n",
      "Edge(5,0,colleague)\n"
     ]
    }
   ],
   "source": [
    "graph.edges.collect.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `triplets` method returns the list of edges, but with some additional annotation.  Now we can recover the vertex labels if we want to see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rxin is the collab of jgonzal\n",
      "franklin is the advisor of rxin\n",
      "istoica is the colleague of franklin\n",
      "franklin is the pi of jgonzal\n",
      "peter is the student of John Doe\n",
      "franklin is the colleague of John Doe\n"
     ]
    }
   ],
   "source": [
    "// Notice that there is a user 0 (for which we have no information) connected to users\n",
    "// 4 (peter) and 5 (franklin).\n",
    "graph.triplets.map(\n",
    "  triplet => triplet.srcAttr._1 + \" is the \" + triplet.attr + \n",
    "  \" of \" + triplet.dstAttr._1\n",
    ").collect.foreach(println(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add our own error handling here by using the `subgraph` method, which is the graph equivalent of `filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rxin is the collab of jgonzal\n",
      "franklin is the advisor of rxin\n",
      "istoica is the colleague of franklin\n",
      "franklin is the pi of jgonzal\n",
      "peter is the student of John Doe\n",
      "franklin is the colleague of John Doe\n",
      "(2,(istoica,prof))\n",
      "(3,(rxin,student))\n",
      "(4,(peter,student))\n",
      "(5,(franklin,prof))\n",
      "(7,(jgonzal,postdoc))\n",
      "rxin is the collab of jgonzal\n",
      "franklin is the advisor of rxin\n",
      "istoica is the colleague of franklin\n",
      "franklin is the pi of jgonzal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@3f2d0076"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,(rxin,student))\n",
      "(5,(franklin,prof))\n",
      "(4,(peter,student))\n",
      "(0,(John Doe,Missing))\n",
      "(7,(jgonzal,postdoc))\n",
      "(2,(istoica,prof))\n"
     ]
    }
   ],
   "source": [
    "// Remove missing vertices as well as the edges to connected to them\n",
    "val validGraph = graph.subgraph(vpred = (id, attr) => attr._2 != \"Missing\")\n",
    "// The valid subgraph will disconnect users 4 and 5 by removing user 0\n",
    "validGraph.vertices.collect.foreach(println(_))\n",
    "validGraph.triplets.map(\n",
    "  triplet => \n",
    "  triplet.srcAttr._1 + \" is the \" + triplet.attr + \n",
    "  \" of \" + triplet.dstAttr._1\n",
    ").collect.foreach(println(_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
